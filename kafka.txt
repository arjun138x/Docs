

introduction and overview of the apache kafka
================================================================
  1. what is apache kafka
    > apache kafka is a distributed streaming platform. it means two things
     1. creating real-time data streams (we can create one or more data streams).
     2. processing real-time data streams
    > another definition of the apache kafka:apache kafka is a highly scalable, 
      and distributed platform for creating and processing streams in real-time
      
  2. how does it work
    >  kafka adopts publisher, subscriber messaging architecture 
          producer ==> messaging broker(kafka) ==> consumer

  3. where does it come from
    > it was developed by linkedin and open sourced in 2011
    > it was implemented to solve the data integration problem.
      > image link  for data integration problem.
        https://www.google.com/search?q=data+integration+problem&source=lnms&tbm=isch&sa=X&ved=2ahUKEwiZrqHlvPn8AhWWSWwGHY-QByIQ_AUoAXoECAEQAw&biw=1366&bih=636&dpr=1#imgrc=BTAbCzKMFHk5zM
 
  4. how it evolved over time
    > it evolved with 5 components
      1. kafka broker - this is a central server system
      2. kafka client - this is a producer and consumer API library
      3. kafka connect - it is  addressing the data integration problem
      4. kafka stream - another library to create real time data streaming applications
      5. kafka KSQL - it is a DB

  5. where does it fit into an enterprise data ecosystem
    > by adopting publisher and subscriber mechanism kafka becomes a data circulating system for our application.
    > it can fit into all microservices architecture applications
  
apache kafka core concepts
================================================
  > Producer
    > Producers write data into topics. These producers are client apps that automatically know which broker and partition to write to.
  > Consumer
    > Consumers are applications on the other ends. They read data from the topic, and just like producers. they also know which topic to read from.
  > Broker
    >  producer and consumer does not contact directly they use the kafka server as agent(broker) to exchange data(messages)
  > Cluster
    > kafka cluster is a group of computers. 
      (or) 
      A Kafka cluster is a system that consists of several Brokers, Topics, and Partitions for both.
  > Topic 
    > topic like a table in DB.
    > Kafka topics are the categories used to organize messages. Each topic has a name that is unique across the entire Kafka cluster. 
      Messages are sent to and read from specific topics. In other words, producers write data to topics, and consumers read data from topics. 
      Kafka topics are multi-subscriber.
  > Partitions
    > Kafka topics are divided into a number of partitions, which contain records in an unchangeable sequence. 
      Each record in a partition is assigned and identified by its unique offset. A topic can also have multiple partition logs. 
      This allows multiple consumers to read from a topic in parallel.
    > A Kafka cluster should have a maximum of 200,000 partitions across all brokers when managed by Zookeeper.
  > Offset
    > offset is a unique sequence id of a messages in a partition. it is automatically assigned by the broker.
    > The offset is an incremental and immutable number, maintained by Kafka.
    > if want to locate a message in cluster. you must know three things
      > 1. topic name 2. partition number 3. offset number
  > Consumer groups
  >  it is a group of consumers. multiple consumer can form a group to share the work load
    (or)
    A consumer group is a set of consumers which cooperate to consume data from some topics. 

kafka connect core concepts
================================================================
  1. what is kafka connect
    > kafka connect is a component of kafka for connecting and moving data between kafka and external system.
    (or)
     the kafka connect is a system. which we can place in between the data source and the kafka cluster.we no need to write any code just we need to configure.
    > we have two types of kafka connectors
      1. source connector
      2. sink connector

  2. how kafka connect work
    > kafka developers already build some frame works for us. by using those we can connect easily. 
      they named it kafka connect framework and it is a open source.
    > as a developer we need write code for two things
      1. source connector // sink connector
      2. source task // sink task

  3. kafka connect scalability
    > kafka connect itself is a cluster.

  4. kafka connect transformations
    > kafka connect is designed for a plane copy between third party systems and kafka 
    > if we want we can transform the each message 
    > single message transformations - SMTs 
      > add a new field in your record using static data or metadata 
      > filter or rename the fields
      > mask some fields with a null value
      > change the record key
      > route the record to a different kafka topic

  5. kafka connect architecture // need to re watch
    > terminology
      1. worker 
      2. connector 
      3. task
